{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dataHDD/chsaikeerthi/2024-chirumamilla\n"
     ]
    }
   ],
   "source": [
    "%matplotlib ipympl\n",
    "import sys\n",
    "\n",
    "import hydra\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "import lightning.pytorch as pl\n",
    "from scipy.stats import gaussian_kde\n",
    "from omegaconf import OmegaConf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "from pathlib import Path\n",
    "from egaznepy.visualize import apply_plot_style\n",
    "from src.data.mocha_timit_datamodule import MTIMITDataModule\n",
    "from src.models.pitch_module import PitchModule\n",
    "from src.models.components.metrics import RCAMetric\n",
    "\n",
    "\n",
    "apply_plot_style(0.9)\n",
    "plt.rcParams['text.usetex'] = False\n",
    "\n",
    "root_dir = Path(globals()['_dh'][0]).parent\n",
    "print(root_dir)\n",
    "import os\n",
    "os.chdir(root_dir)\n",
    "\n",
    "#config_path_predict = 'logs/debug/runs/2024-05-29_17-03-54/.hydra/config.yaml'\n",
    "config_path_predict = 'weights/joint/2024-05-29_17-03-54/.hydra/config.yaml'\n",
    "#ckpt_path = 'logs/debug/runs/2024-05-29_17-03-54/checkpoints/epoch_135.ckpt'\n",
    "ckpt_path = 'weights/joint/2024-05-29_17-03-54/checkpoints/epoch_135.ckpt'\n",
    "\n",
    "#config_path_eval = 'logs/eval/runs/2024-06-02_17-08-12/.hydra/config.yaml'\n",
    "config_path_eval = 'logs/eval/runs/2024-07-01_13-23-14/.hydra/config.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dataHDD/chsaikeerthi/2024-chirumamilla/myenv/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'extractor' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['extractor'])`.\n",
      "/dataHDD/chsaikeerthi/2024-chirumamilla/myenv/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'encoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['encoder'])`.\n",
      "You have turned on `Trainer(detect_anomaly=True)`. This will significantly slow down compute speed and is recommended only for model debugging.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_predict_batches=1)` was configured so 1 batch will be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "Data directory: data/\n",
      "Should implement the code to check if data is already downloaded and extracted.for TIMIT\n",
      "Data prepared successfully.\n",
      "Data folder: data/TIMIT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at weights/joint/2024-05-29_17-03-54/checkpoints/epoch_135.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at weights/joint/2024-05-29_17-03-54/checkpoints/epoch_135.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set length: 5039\n",
      "Validation set length: 630\n",
      "Test set length: 629\n",
      "Data set-up done successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dataHDD/chsaikeerthi/2024-chirumamilla/myenv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=95` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dbc856052d4472fab5fe9197ae20911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dataHDD/chsaikeerthi/2024-chirumamilla/myenv/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:44: attribute 'encoder' removed from hparams because it cannot be pickled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "Data directory: data/\n",
      "Should implement the code to check if data is already downloaded and extracted.for TIMIT\n",
      "Data prepared successfully.\n",
      "Data folder: data/TIMIT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set-up done successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22a0d5658d40447786b30254c4d696e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config_predict = OmegaConf.load(config_path_predict)\n",
    "datamodule = hydra.utils.instantiate(config_predict.data, slice_length=10)\n",
    "pitch_module: PitchModule = hydra.utils.instantiate(config_predict.model)\n",
    "\n",
    "config_eval = OmegaConf.load(config_path_eval)\n",
    "datamodule = hydra.utils.instantiate(config_eval.data, slice_length=10)\n",
    "amazon_module: PitchModule = hydra.utils.instantiate(config_eval.model)\n",
    "del config_predict.trainer.default_root_dir\n",
    "del config_eval.trainer.default_root_dir\n",
    "config_predict.trainer.limit_predict_batches = 1\n",
    "\n",
    "trainer = hydra.utils.instantiate(config_predict.trainer) \n",
    "arr_predict = trainer.predict(model=pitch_module, datamodule=datamodule, ckpt_path=ckpt_path)\n",
    "arr_eval = trainer.predict(model=amazon_module, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the first 4 elements - our model\n",
    "pitches_predict = arr_predict[0][0:4] # these are the values predicted from our model\n",
    "pitches_eval = arr_eval[0][0:4] # these are the values from the opus model\n",
    "# gt\n",
    "\n",
    "corresponding_data = next(iter(datamodule.test_dataloader())) # this is coming from the data module, it has speech pitch from the consensustruth and probability from the consensus truth \n",
    "corresponding_audio = corresponding_data[0][0:4] # this is the audio or the .wav file\n",
    "pitches_gt = corresponding_data[1][0:4] # this is the pitch from the consensus truth\n",
    "probability_gt = corresponding_data[2][0:4] # this is the probability from the consensus truth\n",
    "pitches_gt = pitch_module.decoder.idx_pitch[pitches_gt.argmax(dim=-1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Trues: 2902\n",
      "Number of Falses: 1098\n",
      "Accuracy: 0.7255\n"
     ]
    }
   ],
   "source": [
    "true_count = torch.eq(pitches_eval, pitches_gt).sum().item()\n",
    "false_count = torch.eq(pitches_eval, pitches_gt).numel() - true_count\n",
    "\n",
    "print(f\"Number of Trues: {true_count}\")\n",
    "print(f\"Number of Falses: {false_count}\")\n",
    "accuracy = true_count / (true_count + false_count)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ours tensor(0.7612)\n"
     ]
    }
   ],
   "source": [
    "rca = RCAMetric()\n",
    "print('Ours', rca(pitches_predict, pitches_gt,probability_gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon tensor(0.4070)\n"
     ]
    }
   ],
   "source": [
    "rca = RCAMetric()\n",
    "print('Amazon', rca(pitches_eval, pitches_gt,probability_gt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
